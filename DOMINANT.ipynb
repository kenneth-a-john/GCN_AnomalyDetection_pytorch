{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3a5f0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import data\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import scipy.io as sio\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "\n",
    "from model import Dominant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ad1eb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_adj(adj):\n",
    "    \"\"\"Symmetrically normalize adjacency matrix.\"\"\"\n",
    "    #co ordinate matrix \n",
    "    adj = sp.coo_matrix(adj)\n",
    "    rowsum = np.array(adj.sum(1))\n",
    "    d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
    "    d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
    "    d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n",
    "    return adj.dot(d_mat_inv_sqrt).transpose().dot(d_mat_inv_sqrt).tocoo()\n",
    "\n",
    "def load_anomaly_detection_dataset(dataset, datadir='data'):\n",
    "    \n",
    "    data_mat = sio.loadmat(f'{datadir}/{dataset}.mat')\n",
    "    adj = data_mat['Network']\n",
    "    feat = data_mat['Attributes']\n",
    "    truth = data_mat['Label']\n",
    "    truth = truth.flatten()\n",
    "\n",
    "    adj_norm = normalize_adj(adj + sp.eye(adj.shape[0]))\n",
    "    adj_norm = adj_norm.toarray()\n",
    "    adj = adj + sp.eye(adj.shape[0])\n",
    "    adj = adj.toarray()\n",
    "    feat = feat.toarray()\n",
    "    return adj_norm, feat, truth, adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "153e9a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from layers import GraphConvolution\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, nfeat, nhid, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.gc1 = GraphConvolution(nfeat, nhid)\n",
    "        self.gc2 = GraphConvolution(nhid, nhid)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x = F.relu(self.gc1(x, adj))\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        x = F.relu(self.gc2(x, adj))\n",
    "\n",
    "        return x\n",
    "\n",
    "class Attribute_Decoder(nn.Module):\n",
    "    def __init__(self, nfeat, nhid, dropout):\n",
    "        super(Attribute_Decoder, self).__init__()\n",
    "\n",
    "        self.gc1 = GraphConvolution(nhid, nhid)\n",
    "        self.gc2 = GraphConvolution(nhid, nfeat)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x = F.relu(self.gc1(x, adj))\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        x = F.relu(self.gc2(x, adj))\n",
    "\n",
    "        return x\n",
    "\n",
    "class Structure_Decoder(nn.Module):\n",
    "    def __init__(self, nhid, dropout):\n",
    "        super(Structure_Decoder, self).__init__()\n",
    "\n",
    "        self.gc1 = GraphConvolution(nhid, nhid)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x = F.relu(self.gc1(x, adj))\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        x = x @ x.T\n",
    "\n",
    "        return x\n",
    "\n",
    "class Dominant(nn.Module):\n",
    "    def __init__(self, feat_size, hidden_size, dropout):\n",
    "        super(Dominant, self).__init__()\n",
    "        \n",
    "        self.shared_encoder = Encoder(feat_size, hidden_size, dropout)\n",
    "        self.attr_decoder = Attribute_Decoder(feat_size, hidden_size, dropout)\n",
    "        self.struct_decoder = Structure_Decoder(hidden_size, dropout)\n",
    "    \n",
    "    def forward(self, x, adj):\n",
    "        # encode\n",
    "        x = self.shared_encoder(x, adj)\n",
    "        # decode feature matrix\n",
    "        x_hat = self.attr_decoder(x, adj)\n",
    "        # decode adjacency matrix\n",
    "        struct_reconstructed = self.struct_decoder(x, adj)\n",
    "        # return reconstructed matrices\n",
    "        return struct_reconstructed, x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f65441f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(adj, A_hat, attrs, X_hat, alpha):\n",
    "    # Attribute reconstruction loss\n",
    "    diff_attribute = torch.pow(X_hat - attrs, 2)\n",
    "    attribute_reconstruction_errors = torch.sqrt(torch.sum(diff_attribute, 1))\n",
    "    attribute_cost = torch.mean(attribute_reconstruction_errors)\n",
    "\n",
    "    # structure reconstruction loss\n",
    "    diff_structure = torch.pow(A_hat - adj, 2)\n",
    "    structure_reconstruction_errors = torch.sqrt(torch.sum(diff_structure, 1))\n",
    "    structure_cost = torch.mean(structure_reconstruction_errors)\n",
    "\n",
    "\n",
    "    cost =  alpha * attribute_reconstruction_errors + (1-alpha) * structure_reconstruction_errors\n",
    "\n",
    "    return cost, structure_cost, attribute_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37d2c888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dominant(dataset=\"BlogCatalog\", hidden_dim=64, epoch=100, lr=5e-3, dropout=0.3, alpha=0.8, device=\"cpu\"):\n",
    "    adj, attrs, label, adj_label = load_anomaly_detection_dataset(dataset)\n",
    "    adj = torch.FloatTensor(adj)\n",
    "    adj_label = torch.FloatTensor(adj_label)\n",
    "    attrs = torch.FloatTensor(attrs)\n",
    "    \n",
    "    model = Dominant(feat_size = attrs.size(1), hidden_size = hidden_dim, dropout = dropout)\n",
    "\n",
    "\n",
    "    if device == 'cuda':\n",
    "        device = torch.device(device)\n",
    "        adj = adj.to(device)\n",
    "        adj_label = adj_label.to(device)\n",
    "        attrs = attrs.to(device)\n",
    "        model = model.cuda()\n",
    "        \n",
    "    \n",
    "    optimizer =  (model.parameters(), lr = lr)\n",
    "    \n",
    "    for epoch in range(epoch):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        A_hat, X_hat = model(attrs, adj)\n",
    "        loss, struct_loss, feat_loss = loss_func(adj_label, A_hat, attrs, X_hat, alpha)\n",
    "        l = torch.mean(loss)\n",
    "        l.backward()\n",
    "        optimizer.step()        \n",
    "        print(\"Epoch:\", '%04d' % (epoch), \"train_loss=\", \"{:.5f}\".format(l.item()), \"train/struct_loss=\", \"{:.5f}\".format(struct_loss.item()),\"train/feat_loss=\", \"{:.5f}\".format(feat_loss.item()))\n",
    "\n",
    "        if epoch%10 == 0 or epoch == epoch - 1:\n",
    "            model.eval()\n",
    "            A_hat, X_hat = model(attrs, adj)\n",
    "            loss, struct_loss, feat_loss = loss_func(adj_label, A_hat, attrs, X_hat, alpha)\n",
    "            score = loss.detach().cpu().numpy()\n",
    "            print(\"Epoch:\", '%04d' % (epoch), 'Auc', roc_auc_score(label, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6fbb613c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0000 train_loss= 3.82228 train/struct_loss= 14.05821 train/feat_loss= 1.26330\n",
      "Epoch: 0000 Auc 0.8090687611160287\n",
      "Epoch: 0001 train_loss= 3.05492 train/struct_loss= 10.46063 train/feat_loss= 1.20349\n",
      "Epoch: 0002 train_loss= 2.68756 train/struct_loss= 8.73441 train/feat_loss= 1.17585\n",
      "Epoch: 0003 train_loss= 2.52950 train/struct_loss= 7.94792 train/feat_loss= 1.17490\n",
      "Epoch: 0004 train_loss= 2.48355 train/struct_loss= 7.71805 train/feat_loss= 1.17492\n",
      "Epoch: 0005 train_loss= 2.47342 train/struct_loss= 7.66737 train/feat_loss= 1.17493\n",
      "Epoch: 0006 train_loss= 2.47558 train/struct_loss= 7.67836 train/feat_loss= 1.17488\n",
      "Epoch: 0007 train_loss= 2.47481 train/struct_loss= 7.67495 train/feat_loss= 1.17478\n",
      "Epoch: 0008 train_loss= 2.47047 train/struct_loss= 7.65333 train/feat_loss= 1.17476\n",
      "Epoch: 0009 train_loss= 2.47022 train/struct_loss= 7.65202 train/feat_loss= 1.17477\n",
      "Epoch: 0010 train_loss= 2.47194 train/struct_loss= 7.66070 train/feat_loss= 1.17475\n",
      "Epoch: 0010 Auc 0.813704950109756\n",
      "Epoch: 0011 train_loss= 2.47247 train/struct_loss= 7.66341 train/feat_loss= 1.17473\n",
      "Epoch: 0012 train_loss= 2.47101 train/struct_loss= 7.65614 train/feat_loss= 1.17473\n",
      "Epoch: 0013 train_loss= 2.46977 train/struct_loss= 7.64989 train/feat_loss= 1.17474\n",
      "Epoch: 0014 train_loss= 2.47037 train/struct_loss= 7.65290 train/feat_loss= 1.17473\n",
      "Epoch: 0015 train_loss= 2.47148 train/struct_loss= 7.65850 train/feat_loss= 1.17473\n",
      "Epoch: 0016 train_loss= 2.46868 train/struct_loss= 7.64446 train/feat_loss= 1.17473\n",
      "Epoch: 0017 train_loss= 2.46901 train/struct_loss= 7.64612 train/feat_loss= 1.17473\n",
      "Epoch: 0018 train_loss= 2.46922 train/struct_loss= 7.64719 train/feat_loss= 1.17473\n",
      "Epoch: 0019 train_loss= 2.46878 train/struct_loss= 7.64501 train/feat_loss= 1.17473\n",
      "Epoch: 0020 train_loss= 2.46903 train/struct_loss= 7.64623 train/feat_loss= 1.17473\n",
      "Epoch: 0020 Auc 0.8141639787229962\n",
      "Epoch: 0021 train_loss= 2.46812 train/struct_loss= 7.64168 train/feat_loss= 1.17473\n",
      "Epoch: 0022 train_loss= 2.46715 train/struct_loss= 7.63684 train/feat_loss= 1.17473\n",
      "Epoch: 0023 train_loss= 2.46759 train/struct_loss= 7.63902 train/feat_loss= 1.17473\n",
      "Epoch: 0024 train_loss= 2.46728 train/struct_loss= 7.63753 train/feat_loss= 1.17472\n",
      "Epoch: 0025 train_loss= 2.46753 train/struct_loss= 7.63876 train/feat_loss= 1.17472\n",
      "Epoch: 0026 train_loss= 2.46817 train/struct_loss= 7.64197 train/feat_loss= 1.17473\n",
      "Epoch: 0027 train_loss= 2.46783 train/struct_loss= 7.64024 train/feat_loss= 1.17473\n",
      "Epoch: 0028 train_loss= 2.46768 train/struct_loss= 7.63948 train/feat_loss= 1.17473\n",
      "Epoch: 0029 train_loss= 2.46761 train/struct_loss= 7.63915 train/feat_loss= 1.17473\n",
      "Epoch: 0030 train_loss= 2.46768 train/struct_loss= 7.63952 train/feat_loss= 1.17472\n",
      "Epoch: 0030 Auc 0.8141153353923393\n",
      "Epoch: 0031 train_loss= 2.46732 train/struct_loss= 7.63770 train/feat_loss= 1.17472\n",
      "Epoch: 0032 train_loss= 2.46763 train/struct_loss= 7.63925 train/feat_loss= 1.17472\n",
      "Epoch: 0033 train_loss= 2.46752 train/struct_loss= 7.63869 train/feat_loss= 1.17472\n",
      "Epoch: 0034 train_loss= 2.46727 train/struct_loss= 7.63745 train/feat_loss= 1.17472\n",
      "Epoch: 0035 train_loss= 2.46698 train/struct_loss= 7.63600 train/feat_loss= 1.17472\n",
      "Epoch: 0036 train_loss= 2.46719 train/struct_loss= 7.63707 train/feat_loss= 1.17472\n",
      "Epoch: 0037 train_loss= 2.46717 train/struct_loss= 7.63693 train/feat_loss= 1.17472\n",
      "Epoch: 0038 train_loss= 2.46704 train/struct_loss= 7.63630 train/feat_loss= 1.17472\n",
      "Epoch: 0039 train_loss= 2.46708 train/struct_loss= 7.63648 train/feat_loss= 1.17472\n",
      "Epoch: 0040 train_loss= 2.46659 train/struct_loss= 7.63405 train/feat_loss= 1.17473\n",
      "Epoch: 0040 Auc 0.8141016330456754\n",
      "Epoch: 0041 train_loss= 2.46734 train/struct_loss= 7.63774 train/feat_loss= 1.17474\n",
      "Epoch: 0042 train_loss= 2.46684 train/struct_loss= 7.63533 train/feat_loss= 1.17472\n",
      "Epoch: 0043 train_loss= 2.46712 train/struct_loss= 7.63672 train/feat_loss= 1.17472\n",
      "Epoch: 0044 train_loss= 2.46688 train/struct_loss= 7.63550 train/feat_loss= 1.17472\n",
      "Epoch: 0045 train_loss= 2.46678 train/struct_loss= 7.63500 train/feat_loss= 1.17473\n",
      "Epoch: 0046 train_loss= 2.46695 train/struct_loss= 7.63588 train/feat_loss= 1.17472\n",
      "Epoch: 0047 train_loss= 2.46698 train/struct_loss= 7.63603 train/feat_loss= 1.17472\n",
      "Epoch: 0048 train_loss= 2.46692 train/struct_loss= 7.63569 train/feat_loss= 1.17472\n",
      "Epoch: 0049 train_loss= 2.46684 train/struct_loss= 7.63533 train/feat_loss= 1.17472\n",
      "Epoch: 0050 train_loss= 2.46698 train/struct_loss= 7.63602 train/feat_loss= 1.17472\n",
      "Epoch: 0050 Auc 0.8141680894269951\n",
      "Epoch: 0051 train_loss= 2.46699 train/struct_loss= 7.63608 train/feat_loss= 1.17472\n",
      "Epoch: 0052 train_loss= 2.46680 train/struct_loss= 7.63511 train/feat_loss= 1.17472\n",
      "Epoch: 0053 train_loss= 2.46681 train/struct_loss= 7.63518 train/feat_loss= 1.17472\n",
      "Epoch: 0054 train_loss= 2.46695 train/struct_loss= 7.63587 train/feat_loss= 1.17472\n",
      "Epoch: 0055 train_loss= 2.46691 train/struct_loss= 7.63564 train/feat_loss= 1.17472\n",
      "Epoch: 0056 train_loss= 2.46666 train/struct_loss= 7.63443 train/feat_loss= 1.17472\n",
      "Epoch: 0057 train_loss= 2.46667 train/struct_loss= 7.63445 train/feat_loss= 1.17472\n",
      "Epoch: 0058 train_loss= 2.46668 train/struct_loss= 7.63451 train/feat_loss= 1.17472\n",
      "Epoch: 0059 train_loss= 2.46675 train/struct_loss= 7.63485 train/feat_loss= 1.17472\n",
      "Epoch: 0060 train_loss= 2.46678 train/struct_loss= 7.63501 train/feat_loss= 1.17472\n",
      "Epoch: 0060 Auc 0.8141677468683287\n",
      "Epoch: 0061 train_loss= 2.46662 train/struct_loss= 7.63421 train/feat_loss= 1.17472\n",
      "Epoch: 0062 train_loss= 2.46671 train/struct_loss= 7.63464 train/feat_loss= 1.17472\n",
      "Epoch: 0063 train_loss= 2.46673 train/struct_loss= 7.63475 train/feat_loss= 1.17472\n",
      "Epoch: 0064 train_loss= 2.46677 train/struct_loss= 7.63495 train/feat_loss= 1.17472\n",
      "Epoch: 0065 train_loss= 2.46636 train/struct_loss= 7.63293 train/feat_loss= 1.17472\n",
      "Epoch: 0066 train_loss= 2.46654 train/struct_loss= 7.63380 train/feat_loss= 1.17472\n",
      "Epoch: 0067 train_loss= 2.46690 train/struct_loss= 7.63563 train/feat_loss= 1.17472\n",
      "Epoch: 0068 train_loss= 2.46675 train/struct_loss= 7.63488 train/feat_loss= 1.17472\n",
      "Epoch: 0069 train_loss= 2.46657 train/struct_loss= 7.63395 train/feat_loss= 1.17472\n",
      "Epoch: 0070 train_loss= 2.46683 train/struct_loss= 7.63528 train/feat_loss= 1.17472\n",
      "Epoch: 0070 Auc 0.8141550721976646\n",
      "Epoch: 0071 train_loss= 2.46673 train/struct_loss= 7.63478 train/feat_loss= 1.17472\n",
      "Epoch: 0072 train_loss= 2.46642 train/struct_loss= 7.63320 train/feat_loss= 1.17472\n",
      "Epoch: 0073 train_loss= 2.46653 train/struct_loss= 7.63377 train/feat_loss= 1.17472\n",
      "Epoch: 0074 train_loss= 2.46643 train/struct_loss= 7.63326 train/feat_loss= 1.17472\n",
      "Epoch: 0075 train_loss= 2.46643 train/struct_loss= 7.63326 train/feat_loss= 1.17472\n",
      "Epoch: 0076 train_loss= 2.46668 train/struct_loss= 7.63450 train/feat_loss= 1.17472\n",
      "Epoch: 0077 train_loss= 2.46677 train/struct_loss= 7.63495 train/feat_loss= 1.17472\n",
      "Epoch: 0078 train_loss= 2.46654 train/struct_loss= 7.63382 train/feat_loss= 1.17472\n",
      "Epoch: 0079 train_loss= 2.46653 train/struct_loss= 7.63378 train/feat_loss= 1.17472\n",
      "Epoch: 0080 train_loss= 2.46650 train/struct_loss= 7.63360 train/feat_loss= 1.17472\n",
      "Epoch: 0080 Auc 0.8141776810696602\n",
      "Epoch: 0081 train_loss= 2.46643 train/struct_loss= 7.63325 train/feat_loss= 1.17472\n",
      "Epoch: 0082 train_loss= 2.46650 train/struct_loss= 7.63363 train/feat_loss= 1.17472\n",
      "Epoch: 0083 train_loss= 2.46643 train/struct_loss= 7.63326 train/feat_loss= 1.17472\n",
      "Epoch: 0084 train_loss= 2.46618 train/struct_loss= 7.63199 train/feat_loss= 1.17472\n",
      "Epoch: 0085 train_loss= 2.46661 train/struct_loss= 7.63417 train/feat_loss= 1.17472\n",
      "Epoch: 0086 train_loss= 2.46660 train/struct_loss= 7.63413 train/feat_loss= 1.17472\n",
      "Epoch: 0087 train_loss= 2.46670 train/struct_loss= 7.63462 train/feat_loss= 1.17472\n",
      "Epoch: 0088 train_loss= 2.46661 train/struct_loss= 7.63415 train/feat_loss= 1.17472\n",
      "Epoch: 0089 train_loss= 2.46639 train/struct_loss= 7.63305 train/feat_loss= 1.17472\n",
      "Epoch: 0090 train_loss= 2.46614 train/struct_loss= 7.63179 train/feat_loss= 1.17472\n",
      "Epoch: 0090 Auc 0.8141927536509902\n",
      "Epoch: 0091 train_loss= 2.46643 train/struct_loss= 7.63328 train/feat_loss= 1.17472\n",
      "Epoch: 0092 train_loss= 2.46641 train/struct_loss= 7.63316 train/feat_loss= 1.17472\n",
      "Epoch: 0093 train_loss= 2.46643 train/struct_loss= 7.63326 train/feat_loss= 1.17472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0094 train_loss= 2.46640 train/struct_loss= 7.63312 train/feat_loss= 1.17472\n",
      "Epoch: 0095 train_loss= 2.46666 train/struct_loss= 7.63441 train/feat_loss= 1.17472\n",
      "Epoch: 0096 train_loss= 2.46642 train/struct_loss= 7.63319 train/feat_loss= 1.17472\n",
      "Epoch: 0097 train_loss= 2.46654 train/struct_loss= 7.63381 train/feat_loss= 1.17472\n",
      "Epoch: 0098 train_loss= 2.46618 train/struct_loss= 7.63202 train/feat_loss= 1.17472\n",
      "Epoch: 0099 train_loss= 2.46686 train/struct_loss= 7.63541 train/feat_loss= 1.17472\n"
     ]
    }
   ],
   "source": [
    "train_dominant()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce29cce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782bc7c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fefb9ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f3cce8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "beed7c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_mat = sio.loadmat(f'data/BlogCatalog.mat')\n",
    "adj = data_mat['Network']\n",
    "feat = data_mat['Attributes']\n",
    "truth = data_mat['Label']\n",
    "truth = truth.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8452d9be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6c74a7ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=uint8), array([4898,  298]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(truth, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d8b0ffdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5196x5196 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 350577 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_norm = normalize_adj(adj + sp.eye(adj.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "68a84290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0012987 , 0.00156096, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.00156096, 0.00187617, 0.00195477, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.00195477, 0.00203666, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.0625    , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.05263158,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.05263158]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_norm.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aee509d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_norm = normalize_adj(adj + sp.eye(adj.shape[0]))\n",
    "adj_norm = adj_norm.toarray()\n",
    "adj = adj + sp.eye(adj.shape[0])\n",
    "adj = adj.toarray()\n",
    "feat = feat.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f8cb3d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0012987 , 0.00156096, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.00156096, 0.00187617, 0.00195477, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.00195477, 0.00203666, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.0625    , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.05263158,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.05263158]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a5045946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_norm[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf48adb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b570fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
